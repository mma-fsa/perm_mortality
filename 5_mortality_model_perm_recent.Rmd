---
title: "Perm Mortality Model"
author: "Mike McPhee Anderson, FSA"
date: "2024-12-18"
output: html_document
---

```{r setup, include=FALSE}

library(glmnet)
library(xgboost)
library(recipes)
library(rpart)
library(rpart.plot)
library(splines)
library(rsample)
library(shapviz)
library(tidyselect)
library(doMC)
library(tidyverse)

source("0_lib.R")
source("0_ga_lib.R")

knitr::opts_chunk$set(echo = TRUE)

```

# Overview

## Models

Within the ILEC data "Perm" (permanent) life insurance category, there
are some major differences in the underwriting / target market that can be inferred via EDA. 
These differences lead us to three distinct models:

 1. *Simplified Issue:* Policies issued after 2005 without any preferred classes are likely simplified
   issue.  These policies are less than $100K face amount, and are likely to have less stringent underwriting.
   
 2. *Fully Underwritten (recent):*  Post-2005 policies are likely to have at least one preferred class, and I recall that blood testing gained traction in the late 1990s.  These policies will also have some underwriting class selection (select period) that is still applicable.
 
 3. *Fully Underwritten (historical):*  Policies prior to 2005 are likely to have little remaining effects from underwriting selection.  Also, this data is unlikely to have preferred classes, and is mostly just smoker vs. non-smoker for underwriting classes.  The majority of it will be smaller face amounts.
 
## Training and Testing Splits

Unfortunately, the ILEC data is aggregated in such a way that makes a typical train / test split cumbersome. While we could sample the exposures and deaths for each aggregated cell, things like fractional exposures and the actuarial custom of setting deaths to have a full year of exposure introduce some opportunities for noise.  

Instead, we'll use the most recent two years of data for testing, and perform cross-validation within the training set by observation year.  This is more closely aligned with what an "unseen observation" is in practice, i.e., another calendar year of data.  

# Setup 

## Load Data

```{r}

face_amount_order <- c(
  "1-9999",
  "10000-24999",
  "25000-49999",
  "50000-99999",
  "100000-249999",
  "250000-499999",
  "500000-999999",
  "1000000-2499999",
  "2500000-4999999",
  "5000000-9999999",
  "10000000+"
)

df_study_data <- read_rds("ilec_perm_recent.rds") %>%
  mutate(
    train_test = ifelse(observation_year >= 2016, "TEST", "TRAIN"),
      # no selection period, just ultimate mortality
    expected_deaths_08_vbt_ult = coalesce(qx * policies_exposed),
    # create ordered factor + integer representation of face amount bands
    face_amount_band = ordered(face_amount_band, levels=!!face_amount_order),
    face_amount_band_int = as.integer(face_amount_band),
    issue_age = attained_age - duration + 1
  ) %>%
  filter(expected_deaths_08_vbt_ult > 0)

```

# Perm Historical Model

## Train Test Split

```{r}

df_ph_data <- df_study_data 

df_ph_data.train <- df_ph_data %>% 
  filter(train_test == "TRAIN")

df_ph_data.test <- df_ph_data %>%
  filter(train_test == "TEST")

df_ph_data %>%
  group_by(train_test) %>%
  summarise(
    n_deaths = sum(number_of_deaths),
    .groups="drop"
  ) %>%
  ungroup() %>%
  mutate(
    pct_deaths = n_deaths / sum(n_deaths)
  )

```

## Xgboost Model

```{r}

df_ph_data.train %>%
  group_by(smoker_status, number_of_preferred_classes, preferred_class) %>%
  summarise(
    n_deaths = sum(number_of_deaths)
  )

```

```{r}

summary(df_ph_data.train)

```

```{r}

# used by the GLM as well
step_my_model_factor_prep <- function(recipe) {
  recipe %>% step_mutate(
    issue_age = pmin(issue_age, 75),
    attained_age = pmin(attained_age, 95),
    # group 3-class with the 2-class, there isn't much of it
    preferred_class = case_when(
      # group super-pref & pref (3-class) as pref in the 2-class
      (number_of_preferred_classes == "3") & (preferred_class %in% c("1", "2")) ~ "1",
      # group standard as standard in the 2-class
      (number_of_preferred_classes == "3") & (preferred_class %in% c("3")) ~ "2",
      # set the NA (smoker distinct) classes to be "standard" in the two class, the
      # number of classes will be available to the model, but this gives it the option
      # of grouping standard in 2 class w/ the non-preferred classes, it also makes
      # default levels cleaner
      (number_of_preferred_classes == "NA") ~ "2",
      TRUE ~ preferred_class
    ),
    # set 3-class as 2-class, since applied the grouping above
    number_of_preferred_classes = case_when(
      number_of_preferred_classes == "3" ~ "2",
      number_of_preferred_classes == "NA" ~ "1",
      TRUE ~ number_of_preferred_classes
    ),
    # set factors w/ default levels
    #number_of_preferred_classes = factor(number_of_preferred_classes, levels=c("2")),
    preferred_class = factor(preferred_class, levels=c("2", "1")),
    smoker_status = factor(smoker_status, levels=c("NONSMOKER", "SMOKER")),
    gender = factor(gender, levels=c("MALE", "FEMALE"))
  ) 
}

ph.xgb.recipe <- recipe(~ issue_age + attained_age + gender + smoker_status + duration +
                          face_amount_band_int + number_of_preferred_classes + preferred_class,
                        data=df_ph_data.train) %>%
  step_my_model_factor_prep() %>%
  step_select(-number_of_preferred_classes) %>%
  step_dummy(all_factor_predictors()) %>%
  prep(df_ph_data.train, retain=F)


get_ph_xgb_mat <- function(ph.xgb.recipe, df_ph_data) {
  
  X_mat <- bake(ph.xgb.recipe, df_ph_data) %>% 
    select(-attained_age) %>%
    as.matrix()
  y_vec <- df_ph_data$number_of_deaths
  offset_vec <- log(df_ph_data$expected_deaths_08_vbt_ult)
  
  list(
    "xgb_mat" = xgb.DMatrix(X_mat, label=y_vec, base_margin=offset_vec),
    "X" = X_mat,
    "y" = y_vec,
    "offset" = offset_vec
  )
}

X.train <- get_ph_xgb_mat(ph.xgb.recipe, df_ph_data.train)
X.test <- get_ph_xgb_mat(ph.xgb.recipe, df_ph_data.test)

```

### Run the inferential model

```{r}

xgb_params <- list(
  "eta" = 0.1,
  "gamma" = 1,
  "max_depth" = 3,
  "subsample" = 0.5,
  "colsample_bytree" = 0.7,
  "objective" = "count:poisson"
)

xgb_model <- xgboost::xgb.train(
  params = xgb_params,
  X.train$xgb_mat,
  nrounds = 1000,
  watchlist = list(validation=X.test$xgb_mat),
  early_stopping_rounds = 10,
  nthread=-1,
  print_every_n = 100
)

## sanity check
list(
  "train a/e" = round(sum(X.train$y) / sum(predict(xgb_model, X.train$xgb_mat)), 3),
  "test a/e" = round(sum(X.test$y) / sum(predict(xgb_model, X.test$xgb_mat)), 3)
)

```

### Identify most important effect(s) and interaction(s)

```{r}

xgboost::xgb.plot.shap(X.test$X, top_n = 6, model=xgb_model, n_col=2)

```

Face amount and attained age interaction is visible from below plot.

```{r}

sv <- shapviz::shapviz(xgb_model,
                       X_pred = X.train$xgb_mat,
                       X = X.train$X,
                       interactions = T)

```

```{r}

plot_data <- tibble(
  issue_age = sv$X$issue_age,
  duration = sv$X$duration,
  factor_duration = sv$S[, "duration"] + sv$S_inter[, "duration", "issue_age"]
) %>%
  group_by(issue_age, duration) %>%
  summarise(factor_duration = mean(factor_duration),
            .groups = "drop") %>%
  mutate(
    age_grp = case_when(
      issue_age < 40 ~ "<40",
      issue_age < 60 ~ "40-59",
      issue_age < 70 ~ "60-69",
      TRUE ~ "70+"
     )
  )

ggplot(plot_data, aes(x=duration, y=factor_duration, color=issue_age, group=issue_age)) +
  facet_wrap(~ age_grp) +
  geom_line()

```

## Build GLM

### Identify spline locations

Eyeball percentiles from SHAP plots and the cumulative percent of claims (percentiles).

 * The aggregated data makes estimating percentiles using built-in functions difficult, so use the plots


```{r}

df_ph_data.train %>%
  group_by(number_of_preferred_classes, preferred_class) %>%
  summarise(
    number_of_deaths = sum(number_of_deaths)
  )

```

### Knot Selection

```{r}

group_model_data <- function(df) {
  df %>%
    group_by(attained_age, duration, issue_age, number_of_preferred_classes,
             preferred_class, smoker_status, face_amount_band_int, gender) %>%
    summarise(
      number_of_deaths = sum(number_of_deaths),
      expected_deaths_08_vbt_ult = sum(expected_deaths_08_vbt_ult),
      .groups="drop"
    ) %>%
    ungroup()
}

model_data.train <- df_ph_data.train %>% group_model_data()
model_data.test <- df_ph_data.test %>% group_model_data()

ph.glmnet.recipe <- recipe(number_of_deaths ~ face_amount_band_int + 
                             attained_age + 
                             duration + 
                             issue_age +
                             gender +
                             number_of_preferred_classes +
                             preferred_class +
                             smoker_status + 
                             expected_deaths_08_vbt_ult,
                           data = model_data.train) %>%
  step_my_model_factor_prep() %>%
  step_mutate(
    log_duration_interp = log_interp_spline(duration, 10, 15, 0.33)
  ) %>%
  prep(model_data.train, retain=F)

model_data.train <- bake(ph.glmnet.recipe, model_data.train) 
model_data.test <- bake(ph.glmnet.recipe, model_data.test)

model_data.train %>%
  summary()

```


```{r}

qtiles <- function(x) {
  unique(quantile(x, probs=seq(0.05, 0.95, by=0.05)))
}

ga_def <- with(model_data.train, {
  ga_knot_search(
    # define formula w/ knot search placeholders
    number_of_deaths ~ preferred_class + 
      smoker_status + 
      gender * ATT_AGE +
      FACE_BAND + 
      log_duration_interp * ISSUE_AGE - 1,
    # offset term
    offset = log(expected_deaths_08_vbt_ult),
    # define knot search
    ATT_AGE = ga_knot_def_ns(
      attained_age,
      qtiles(attained_age)),
    FACE_BAND = ga_knot_def_bs(
      face_amount_band_int, 
      qtiles(face_amount_band_int)
    ),
    ISSUE_AGE = ga_knot_def_ns(
      issue_age, 
      qtiles(issue_age)))
})

total_bits <- sum(vapply(ga_def$knot_definitions, function(x) { x$n_bits }, 
                     FUN.VALUE = c(0)))

fake_bitstr <- rbinom(total_bits, 1, prob=0.5)

ga_def$eval_bitstr(fake_bitstr)

```



```{r}

best_model <- GA::ga(type="binary", 
       ga_def$eval_bitstr, 
       popSize=10, 
       nBits = ga_def$total_bits, 
       maxiter = 50, 
       parallel = F,
       pmutation = 0.3,
       elitism = 1,
       suggestions = ga_def$initial_suggestions,
       pcrossover=0.7)

```

```{r}

ga_def$bitstr_to_formula(best_model@solution)

```

```{r}

ga_def$bitstr_to_formula(best_model@solution)

```

### Setup GLMNet recipe

```{r}

best_formula <- number_of_deaths ~ 
  preferred_class + 
  smoker_status + 
  splines::bs(face_amount_band_int, Boundary.knots = c(1, 11), knots = c(2, 9), degree = 1) + 
  # gender + attained age interaction
  gender * 
    splines::ns(attained_age, Boundary.knots = c(25, 95), knots = c(29, 33, 41, 63, 69)) + 
  # selection factor / policy year (UW) and issue age interaction
  log_duration_interp * 
    splines::ns(issue_age, Boundary.knots = c(18, 75), knots = c(31, 39, 64)) - 1

X_mat <- model.matrix(best_formula, data=model_data.train)

df_wts <- tibble(
  term_name = colnames(X_mat)) %>%
  mutate(
    lower_limits = case_when(
      stringr::str_detect(term_name, fixed("log_duration_interp")) ~ 0,
      TRUE ~ -Inf
    ),
    upper_limits = case_when(
      (stringr::str_detect(term_name, fixed("issue_age"))) &
        !(stringr::str_detect(term_name, fixed("log_duration_interp"))) ~ 0,
      TRUE ~ Inf
    )
  )

final_model <- glmnet::glmnet(
    X_mat,
    model_data.train$number_of_deaths,
    offset = log(model_data.train$expected_deaths_08_vbt_ult),
    family = "poisson",
    intercept = T
  )
  
aic_bic <- calc_aic_bic_glmnet(final_model)

min(aic_bic$BIC)

```


### Plot Deviance Ratio vs. Lambda

```{r}

BEST_LAMBDA_IDX <- 80

best_lambda_val <- final_model$lambda[BEST_LAMBDA_IDX]
plot(final_model$dev.ratio, type="l")
points(BEST_LAMBDA_IDX, final_model$dev.ratio[BEST_LAMBDA_IDX])

```

### Append Predictions

```{r}

model_data.train[["pred_deaths"]] <- predict(
  final_model, 
  newx = model.matrix(best_formula, data=model_data.train),
  s = best_lambda_val,
  type="response",
  newoffset = log(model_data.train$expected_deaths_08_vbt_ult)) %>%
  c()

model_data.test[["pred_deaths"]] <- predict(
  final_model, 
  newx = model.matrix(best_formula, data=model_data.test),
  s = best_lambda_val,
  type="response",
  newoffset = log(model_data.test$expected_deaths_08_vbt_ult)) %>%
  c()

list(
  "train A/E" = sum(model_data.train$number_of_deaths) / sum(model_data.train$pred_deaths),
  "test A/E" = sum(model_data.test$number_of_deaths) / sum(model_data.test$pred_deaths)
)


```

### Check Model w/ Decision Tree

#### Training Set

```{r fig.width=10}

prep_rpart_data <- function(df) {
  X <- df %>% 
    select(-number_of_deaths, 
           -expected_deaths_08_vbt_ult, 
           -log_duration_interp,
           -pred_deaths)
  
  y <- df[, c("pred_deaths", "number_of_deaths")] %>%
    as.matrix()
  
  list(
    "X" = X,
    "y" = y
  )
}

rpart_data <- model_data.train %>%
  prep_rpart_data

model_errors <- rpart_data$y

rpart_model <- rpart(
  model_errors ~ .,
  data=rpart_data$X,
  method="poisson",
  control = rpart.control(cp=0.0001, maxdepth = 3))

rpart.plot(rpart_model, digits=4)
```

#### Testing Set

```{r fig.width=10}

rpart_data <- model_data.test %>%
  prep_rpart_data()

model_errors <- rpart_data$y

rpart_model <- rpart(
  model_errors ~ .,
  data=rpart_data$X,
  method="poisson",
  control = rpart.control(cp=0.0001, maxdepth = 3))

rpart.plot(rpart_model, digits=3)


```

### Look for patterns in misprediction



### Examine model factors

```{r}

best_coefs <- predict.glmnet(
  final_model, newx=X_mat, s=best_lambda_val, type = "coefficients"
)

predictor_groups <- tibble(
  term_name = best_coefs@Dimnames[[1]]
  ) %>%
  mutate(
    term_group = case_when(
      stringr::str_detect(term_name, fixed("Intercept")) ~ "factor_base_rate",
      stringr::str_detect(term_name, fixed("preferred_class")) ~ "factor_preferred_class",
      stringr::str_detect(term_name, fixed("smoker_status")) ~ "factor_smoker_status",
      stringr::str_detect(term_name, fixed("gender")) |
        stringr::str_detect(term_name, fixed("attained_age")) ~ "factor_gender_x_attained_age",
      stringr::str_detect(term_name, fixed("issue_age")) |
        stringr::str_detect(term_name, fixed("duration")) ~ "factor_issue_age_x_duration",
      stringr::str_detect(term_name, fixed("face_amount_band_int")) ~ "factor_face_amount"
    )
  )

predictor_groups %>% view()
```



```{r}

pred_grid <- expand.grid(
  face_amount_band_int = seq(min(df_ph_data.train$face_amount_band_int), max(df_ph_data.train$face_amount_band_int), by=1),
  attained_age = seq(min(df_ph_data.train$attained_age), max(df_ph_data.train$attained_age), by=1),
  duration = seq(min(df_ph_data.train$duration), max(df_ph_data.train$duration), by=1),
  issue_age = seq(min(df_ph_data.train$issue_age), max(df_ph_data.train$issue_age), by=1),
  gender = unique(df_ph_data.train$gender),
  number_of_preferred_classes = unique(df_ph_data.train$number_of_preferred_classes),
  preferred_class = unique(df_ph_data.train$preferred_class),
  smoker_status = unique(df_ph_data.train$smoker_status),
  number_of_deaths = 0, 
  stringsAsFactors = F) %>% 
  filter(
    issue_age + duration - 1 == attained_age,
    ((smoker_status == "NONSMOKER") | ((smoker_status == "SMOKER") & (number_of_preferred_classes == "2"))),
    (
      ((number_of_preferred_classes == "2") & (preferred_class %in% c("1", "2"))) |
      ((number_of_preferred_classes == "3") & (preferred_class %in% c("1", "2", "3")))
    )) %>%
  prep_log_interp()

X_pred_grid <- cbind(
  rep(1, nrow(pred_grid)),
  model.matrix(best_formula, data=pred_grid)
)

coeff_diag <- rep(0, best_coefs@Dim[1])
coeff_diag[best_coefs@i + 1] <- best_coefs@x
coeff_diag <- diag(coeff_diag)

pred_mat <- X_pred_grid %*% coeff_diag
colnames(pred_mat) <- best_coefs@Dimnames[[1]]

pred_df <- pred_mat %>%
  as.data.frame() %>%
  mutate(
    pred_idx = row_number()) %>%
  pivot_longer(
    cols=-c(pred_idx), 
    names_to = "term_name", 
    values_to = "term_value") %>%
  inner_join(predictor_groups, by="term_name") %>%
  group_by(pred_idx, term_group) %>%
  summarise(
    total_value = exp(sum(term_value)),
    .groups = "drop"
  ) %>%
  ungroup() %>%
  pivot_wider(
    id_cols = pred_idx, names_from = "term_group", values_from = "total_value"
  )

full_pred_df <- bind_cols(
  pred_grid,
  pred_df
)

```

```{r}

plot_data <- full_pred_df %>%
  select(issue_age, duration, factor_issue_age_x_duration, factor_base_rate) %>%
  distinct()

ggplot(plot_data, aes(x=duration, y=factor_issue_age_x_duration, group=issue_age, color=issue_age)) +
  geom_line()

```

### Evaluate Model

```{r}

colnames(model_data.train)

```



