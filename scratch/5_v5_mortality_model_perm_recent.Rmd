---
title: "Perm Mortality Model"
author: "Mike McPhee Anderson, FSA"
date: "2024-12-18"
output: html_document
---

```{r setup, include=FALSE}

library(glmnet)
library(xgboost)
library(recipes)
library(rpart)
library(rpart.plot)
library(splines)
library(rsample)
library(shapviz)
library(tidyselect)
library(doMC)
library(tidyverse)
library(nloptr)

knitr::opts_chunk$set(echo = TRUE)

```

# Overview

## Models

Within the ILEC data "Perm" (permanent) life insurance category, there
are some major differences in the underwriting / target market that can be inferred via EDA. 
These differences lead us to three distinct models:

 1. *Simplified Issue:* Policies issued after 2005 without any preferred classes are likely simplified
   issue.  These policies are less than $100K face amount, and are likely to have less stringent underwriting.
   
 2. *Fully Underwritten (recent):*  Post-2005 policies are likely to have at least one preferred class, and I recall that blood testing gained traction in the late 1990s.  These policies will also have some underwriting class selection (select period) that is still applicable.
 
 3. *Fully Underwritten (historical):*  Policies prior to 2005 are likely to have little remaining effects from underwriting selection.  Also, this data is unlikely to have preferred classes, and is mostly just smoker vs. non-smoker for underwriting classes.  The majority of it will be smaller face amounts.
 
## Training and Testing Splits

Unfortunately, the ILEC data is aggregated in such a way that makes a typical train / test split cumbersome. While we could sample the exposures and deaths for each aggregated cell, things like fractional exposures and the actuarial custom of setting deaths to have a full year of exposure introduce some opportunities for noise.  

Instead, we'll use the most recent two years of data for testing, and perform cross-validation within the training set by observation year.  This is more closely aligned with what an "unseen observation" is in practice, i.e., another calendar year of data.  

# Setup 

## Load Data

```{r}

face_amount_order <- c(
  "1-9999",
  "10000-24999",
  "25000-49999",
  "50000-99999",
  "100000-249999",
  "250000-499999",
  "500000-999999",
  "1000000-2499999",
  "2500000-4999999",
  "5000000-9999999",
  "10000000+"
)

df_study_data <- read_rds("ilec_perm_recent.rds") %>%
  mutate(
    train_test = ifelse(observation_year >= 2016, "TEST", "TRAIN"),
      # no selection period, just ultimate mortality
    expected_deaths_08_vbt_ult = coalesce(qx * policies_exposed),
    # create ordered factor + integer representation of face amount bands
    face_amount_band = ordered(face_amount_band, levels=!!face_amount_order),
    face_amount_band_int = as.integer(face_amount_band),
    issue_age = attained_age - duration + 1
  ) %>%
  filter(expected_deaths_08_vbt_ult > 0)

```

# Perm Historical Model

## Train Test Split

```{r}

df_ph_data <- df_study_data 

df_ph_data.train <- df_ph_data %>% 
  filter(train_test == "TRAIN")

df_ph_data.test <- df_ph_data %>%
  filter(train_test == "TEST")

df_ph_data %>%
  group_by(train_test) %>%
  summarise(
    n_deaths = sum(number_of_deaths),
    .groups="drop"
  ) %>%
  ungroup() %>%
  mutate(
    pct_deaths = n_deaths / sum(n_deaths)
  )

```



```{r}

summary(df_ph_data.train)

```

```{r}

log_interp_spline <- function(v, interp_start, interp_end, interp_power) {
  c1 <- pmin(1, pmax(0, interp_end - v) / (interp_end - interp_start))^interp_power
  c1 * log(v) + (1-c1) * log(interp_end)
}

curr_ns_breaks <- c(-Inf, seq(45, 75, by=10), Inf)
curr_sm_breaks <- c(-Inf, seq(45, 75, by=10), Inf)
ns_spline_params <- c(10, 15, 0.5)
sm_spline_params <- c(10, 15, 0.5)

group_model_data <- function(df) {
  df %>%
    group_by(attained_age, duration, issue_age, number_of_preferred_classes,
             preferred_class, smoker_status, face_amount_band_int, gender) %>%
    summarise(
      number_of_deaths = sum(number_of_deaths),
      expected_deaths_08_vbt_ult = sum(expected_deaths_08_vbt_ult),
      .groups="drop"
    ) %>%
    ungroup() %>%
    mutate(
      sm_ind = ifelse(smoker_status == "SMOKER", 1, 0),
      ns_ind = ifelse(smoker_status == "NONSMOKER", 1, 0),
      AGE_GRPS_NS = cut(issue_age, breaks = curr_ns_breaks),
      AGE_GRPS_SM = cut(issue_age, breaks = curr_sm_breaks)
    )
}

model_data.train <- df_ph_data.train %>% group_model_data()
model_data.test <- df_ph_data.test %>% group_model_data()

```


```{r}

exp_basis_formula <- number_of_deaths ~ 
  sm_ind * splines::ns(attained_age, 
                              Boundary.knots = c(25, 95), 
                              knots = c(35, 40, 45, 52, 70, 80)) +
  ns_ind:AGE_GRPS_NS +
  sm_ind:AGE_GRPS_SM - 1

default_interp_params <- c(10, 15, 0.5)

log_interp_params <- list(
  "ns_ind:AGE_GRPS_NS(-Inf,45]" = default_interp_params,
  "ns_ind:AGE_GRPS_NS(45,55]" = default_interp_params,                                         
  "ns_ind:AGE_GRPS_NS(55,65]" = default_interp_params,                                              
  "ns_ind:AGE_GRPS_NS(65,75]" = default_interp_params,                                               
  "ns_ind:AGE_GRPS_NS(75, Inf]" = default_interp_params,
  "sm_ind:AGE_GRPS_SM(45,55]" = default_interp_params,
  "sm_ind:AGE_GRPS_SM(55,65]" = default_interp_params,
  "sm_ind:AGE_GRPS_SM(65,75]" = default_interp_params,
  "sm_ind:AGE_GRPS_SM(75, Inf]" = c(5, 10, 6) 
)

create_design_mat <- function(df, exp_basis_formula, log_interp_params) {
  
  mm_train <- model.matrix(
    exp_basis_formula,
    data = model_data.train)
  
  interp_param_mat <- matrix(
    0, 
    ncol = length(log_interp_params),
    nrow = nrow(mm_train))
  
  col_i <- 1
  colnames(interp_param_mat) <- paste0(names(log_interp_params), ":log_interp")
  
  for (col_name in names(log_interp_params)) {
  
    interp_def <- log_interp_params[[col_name]]
    
    print(col_name)
    interp_param_mat[, col_i] <- log_interp_spline(
      model_data.train$duration,
      interp_def[1],
      interp_def[2],
      interp_def[3]
    ) * mm_train[, col_name]
    
    col_i <- col_i + 1
  }

  cbind(mm_train, interp_param_mat)
}

dmat.train <- create_design_mat(
  model_data.train,
  exp_basis_formula,
  log_interp_params 
) 

dmat.test <- create_design_mat(
  model_data.test,
  exp_basis_formula,
  log_interp_params 
) 

dmat.train %>% colnames()

```



```{r}

intercept_idx <- which(
  stringr::str_detect(colnames(dmat.train), fixed("AGE_GRPS_")) &
    !(stringr::str_detect(colnames(dmat.train), fixed("log_interp")))
)

slope_idx <- which(
  stringr::str_detect(colnames(dmat.train), fixed("AGE_GRPS_")) &
    (stringr::str_detect(colnames(dmat.train), fixed("log_interp")))
)

model_limits <- tibble(
  upper_limits = rep(Inf, ncol(dmat.train)),
  lower_limits = rep(-Inf, ncol(dmat.train)),
  penalty = rep(1, ncol(dmat.train))
) 

model_limits[intercept_idx, "upper_limits"] <- 0
model_limits[slope_idx, "lower_limits"] <- 0
model_limits[slope_idx, "upper_limits"] <- 1 / log(15)
model_limits[c(intercept_idx, slope_idx), "penalty"] <- 0.1

y.train <- model_data.train$number_of_deaths
y.test <- model_data.test$number_of_deaths

offset.train <- log(model_data.train$expected_deaths_08_vbt_ult)
offset.test <- log(model_data.test$expected_deaths_08_vbt_ult)

model_fit <- glmnet::glmnet(
  dmat.train,
  y.train,
  offset = offset.train,
  family = "poisson",
  intercept = T,
  lower.limits = model_limits$lower_limits,
  upper.limits = model_limits$upper_limits,
  penalty.factor = model_limits$penalty
)

BEST_COEF_IDX <- 80

best_coef <- coef(model_fit)[, BEST_COEF_IDX]

all(best_coef[1 + intercept_idx] < 0) & 
  all(best_coef[1 + slope_idx] > 0)

best_coef %>% view()

```

```{r}

init_param <- best_coef 

# calculate (negative) the value @ 15
intercept_adjustment <- -1*(best_coef[intercept_idx] + 
     best_coef[slope_idx] * log(15))

# subtract it from the intercept so we are at 0 (1.0x) @ duration 15 
init_param[intercept_idx] <- init_param[intercept_idx] + intercept_adjustment

init_param

```



```{r}

model_data.train[["warmup_pred"]] <- predict(
  model_fit,
  newx = dmat.train,
  newoffset = offset.train
)

```


## Fit Model with L-BFGS

```{r}

make_likelihood <- function(X, y, offset, l2=50) {
  
  l2_penalty <- rep(l2, ncol(X))
  l2_penalty[1] <- 0
  function(beta) {
    Xbeta <- X %*% beta + offset
    #-(sum(y * Xbeta - exp(Xbeta)) - .5 * sum(beta^2 * l2_penalty))
    -(sum(y * Xbeta - exp(Xbeta)))
  }  
}

make_gradient <- function(X, y, offset, l2=50) {
  l2_penalty <- rep(l2, ncol(X))
  l2_penalty[1] <- 0
  function(beta) {
    Xbeta <- X %*% beta + offset
    #-(crossprod(X, (y - exp(Xbeta))) - beta * l2_penalty)
    -(crossprod(X, (y - exp(Xbeta))))
  }  
}

```


```{r}

offset_params <- c(slope_idx, intercept_idx)
training_params <- -1 * offset_params

X_mat <- dmat.train[, training_params]

X_mat <- cbind(
    rep(1, nrow(X_mat)),
    X_mat)

colnames(X_mat)[1] <- "(Intercept)"
colnames(X_mat)

```

```{r}

new_offset.train <- dmat.train[, offset_params] %*% init_param[offset_params + 1] + offset.train

sum(y.train) / sum(exp(rowSums(X_mat %*% init_param[training_params + 1]) + new_offset.train))

```


```{r}

l2 = 0

obj_fn <- make_likelihood(
  X_mat, y.train, new_offset.train, l2
)

grad_fn <- make_gradient(
  X_mat, y.train, new_offset.train, l2
)

```


```{r}

training_param_idx <- vapply(colnames(X_mat), 
       function(c_name) which(c_name == colnames(X_mat)), 
       c(1))

optim_start <- init_param[training_param_idx]

```


```{r}

# x3 - x4 <= 0 -> x3 <= x4

# x4 > x3 -> x3 - x4 < 0

# less than or equal to zero
hin <- function(x) {
  ineq_vals <- rep(0, length(x))
  ineq_vals[4] <- x[3] - x[4]
  ineq_vals[5] <- x[4] - x[5]
  ineq_vals[5] <- x[5] - x[6]
  ineq_vals[6] <- x[6] - x[7]
  ineq_vals[7] <- x[7] - x[8]
  ineq_vals[8] <- x[8] - x[7]
  ineq_vals[9] <- x[9] - x[8]
  ineq_vals
}

heq <- function(x) { 
  eq_vals <- rep(0, length(x))
  eq_vals
}

this_init <- init_param
this_init[1] <- 0

optim_res <- nloptr::auglag(
  optim_start, 
  obj_fn, 
  gr = grad_fn, 
  hin = hin, 
  heq = hin, 
  deprecatedBehavior = FALSE,
  control=nl.opts(list(maxeval = 10000)),
  localsolver = "LBFGS")

optim_res

```

```{r}
names(optim_res$par) <- names(optim_start)

optim_res$par[3:9]
```


```{r}

model_data.train[["final_pred"]] <- exp(X_mat %*% optim_res$par + new_offset.train)

sum(model_data.train$number_of_deaths) / 
  sum(model_data.train[["final_pred"]])

```

```{r}

test_attage <- seq(25, 95)

X_attage <- splines::ns(test_attage, 
            Boundary.knots = c(25, 95), 
            knots = c(35, 40, 45, 52, 70, 80))

plot(
  test_attage,
  X_attage %*% optim_res$par[3:9],
  type="l"
)



```


```{r}

plot_data <- model_data.train %>%
  group_by(attained_age, smoker_status) %>%
  summarise(
    ae = sum(number_of_deaths) / sum(final_pred),
    .groups="drop"
  ) %>%
  ungroup()


ggplot(plot_data, aes(x=attained_age, y=ae, color=smoker_status, group=smoker_status)) +
  geom_line()


```

```{r}


plot_data <- model_data.train %>%
  group_by(AGE_GRPS_NS, smoker_status, duration) %>%
  summarise(
    ae = sum(number_of_deaths) / sum(final_pred),
    .groups="drop"
  ) %>%
  ungroup()


ggplot(plot_data, aes(x=duration, y=ae, color=smoker_status, group=smoker_status)) +
  facet_wrap(~ AGE_GRPS_NS, scales = "free_y") +
  geom_line() +
  geom_hline(yintercept = 1) +
  theme_bw()


```

